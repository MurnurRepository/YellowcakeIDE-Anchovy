// Simple standalone test for Yellercake compiler concepts
use std::fmt;

#[derive(Debug, Clone, PartialEq)]
enum TokenType {
    Entity,
    Circle,
    Radius,
    Print,
    String(String),
    Number(f64),
    Identifier(String),
    LParen,
    RParen,
    Colon,
    Comma,
    EOF,
}

#[derive(Debug, Clone)]
struct Token {
    token_type: TokenType,
    lexeme: String,
    line: usize,
}

impl Token {
    fn new(token_type: TokenType, lexeme: String, line: usize) -> Self {
        Self { token_type, lexeme, line }
    }
}

struct Lexer {
    source: String,
    tokens: Vec<Token>,
    start: usize,
    current: usize,
    line: usize,
}

impl Lexer {
    fn new(source: String) -> Self {
        Self {
            source,
            tokens: Vec::new(),
            start: 0,
            current: 0,
            line: 1,
        }
    }
    
    fn tokenize(&mut self) -> Result<Vec<Token>, String> {
        while !self.is_at_end() {
            self.start = self.current;
            if let Err(e) = self.scan_token() {
                return Err(e);
            }
        }
        
        self.tokens.push(Token::new(TokenType::EOF, "".to_string(), self.line));
        Ok(self.tokens.clone())
    }
    
    fn scan_token(&mut self) -> Result<(), String> {
        let c = self.advance();
        
        match c {
            '(' => self.add_token(TokenType::LParen),
            ')' => self.add_token(TokenType::RParen),
            ':' => self.add_token(TokenType::Colon),
            ',' => self.add_token(TokenType::Comma),
            '"' => self.string()?,
            ' ' | '\r' | '\t' => {},
            '\n' => self.line += 1,
            _ => {
                if c.is_digit(10) {
                    self.number();
                } else if c.is_alphabetic() {
                    self.identifier();
                } else {
                    return Err(format!("Unexpected character '{}' on line {}", c, self.line));
                }
            }
        }
        Ok(())
    }
    
    fn advance(&mut self) -> char {
        let c = self.source.chars().nth(self.current).unwrap_or('\0');
        self.current += 1;
        c
    }
    
    fn add_token(&mut self, token_type: TokenType) {
        let text = self.source[self.start..self.current].to_string();
        self.tokens.push(Token::new(token_type, text, self.line));
    }
    
    fn string(&mut self) -> Result<(), String> {
        while self.peek() != '"' && !self.is_at_end() {
            if self.peek() == '\n' {
                self.line += 1;
            }
            self.advance();
        }
        
        if self.is_at_end() {
            return Err(format!("Unterminated string on line {}", self.line));
        }
        
        self.advance(); // closing "
        
        let value = self.source[(self.start + 1)..(self.current - 1)].to_string();
        self.add_token(TokenType::String(value));
        Ok(())
    }
    
    fn number(&mut self) {
        while self.peek().is_digit(10) {
            self.advance();
        }
        
        if self.peek() == '.' && self.peek_next().is_digit(10) {
            self.advance();
            while self.peek().is_digit(10) {
                self.advance();
            }
        }
        
        let value: f64 = self.source[self.start..self.current].parse().unwrap();
        self.add_token(TokenType::Number(value));
    }
    
    fn identifier(&mut self) {
        while self.peek().is_alphanumeric() {
            self.advance();
        }
        
        let text = &self.source[self.start..self.current];
        let token_type = match text {
            "entity" => TokenType::Entity,
            "circle" => TokenType::Circle,
            "radius" => TokenType::Radius,
            "print" => TokenType::Print,
            _ => TokenType::Identifier(text.to_string()),
        };
        
        self.add_token(token_type);
    }
    
    fn peek(&self) -> char {
        self.source.chars().nth(self.current).unwrap_or('\0')
    }
    
    fn peek_next(&self) -> char {
        self.source.chars().nth(self.current + 1).unwrap_or('\0')
    }
    
    fn is_at_end(&self) -> bool {
        self.current >= self.source.len()
    }
}

fn main() {
    println!("üöÄ Testing Yellercake Compiler Core Logic");
    println!("==========================================");
    
    let test_code = r#"
entity circle1 circle(radius: 50)
print "Hello, Yellercake!"
"#;
    
    println!("Test code:");
    println!("{}", test_code);
    println!("---");
    
    let mut lexer = Lexer::new(test_code.to_string());
    
    match lexer.tokenize() {
        Ok(tokens) => {
            println!("‚úÖ Tokenization successful!");
            println!("Found {} tokens:", tokens.len());
            
            for (i, token) in tokens.iter().enumerate() {
                println!("  {}: {:?}", i, token);
            }
            
            println!("\nüéâ Core compiler logic is working!");
            println!("The full Yellercake compiler should work once the file lock issue is resolved.");
        }
        Err(e) => {
            println!("‚ùå Tokenization failed: {}", e);
        }
    }
}
